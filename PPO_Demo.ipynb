{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # -1 for cpu, currently available gpu 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 12:46:57.330514: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-30 12:46:57.445243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-30 12:46:57.445309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-30 12:46:57.446739: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-30 12:46:57.475530: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-30 12:46:59.971793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "from dataclasses import dataclass\n",
    "import datetime, pytz\n",
    "import enum\n",
    "import functools\n",
    "import os\n",
    "import os\n",
    "import time\n",
    "from typing import Final, Sequence\n",
    "from typing import Optional\n",
    "from typing import Union, cast\n",
    "os.environ['WRAPT_DISABLE_EXTENSIONS'] = 'true'\n",
    "\n",
    "from absl import logging\n",
    "import gin\n",
    "import gin\n",
    "from matplotlib import patches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import reverb\n",
    "import mediapy as media\n",
    "from IPython.display import clear_output\n",
    "from smart_control.environment import environment\n",
    "from smart_control.proto import smart_control_building_pb2\n",
    "from smart_control.proto import smart_control_normalization_pb2\n",
    "from smart_control.reward import electricity_energy_cost\n",
    "from smart_control.reward import natural_gas_energy_cost\n",
    "from smart_control.reward import setpoint_energy_carbon_regret\n",
    "from smart_control.reward import setpoint_energy_carbon_reward\n",
    "from smart_control.simulator import randomized_arrival_departure_occupancy\n",
    "from smart_control.simulator import rejection_simulator_building\n",
    "from smart_control.simulator import simulator_building\n",
    "from smart_control.simulator import step_function_occupancy\n",
    "from smart_control.simulator import stochastic_convection_simulator\n",
    "from smart_control.utils import bounded_action_normalizer\n",
    "from smart_control.utils import building_renderer\n",
    "from smart_control.utils import controller_reader\n",
    "from smart_control.utils import controller_writer\n",
    "from smart_control.utils import conversion_utils\n",
    "from smart_control.utils import observation_normalizer\n",
    "from smart_control.utils import reader_lib\n",
    "from smart_control.utils import writer_lib\n",
    "from smart_control.utils import histogram_reducer\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from smart_control.utils import environment_utils\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.ppo import ppo_agent\n",
    "from tf_agents.agents.ppo import ppo_clip_agent\n",
    "from tf_agents.agents.ppo import ppo_actor_network\n",
    "from tf_agents.environments import parallel_py_environment\n",
    "from tf_agents.networks import value_network\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.keras_layers import inner_reshape\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.networks import nest_map\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.policies import tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.train import actor\n",
    "from tf_agents.train import learner\n",
    "from tf_agents.train import triggers\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import train_utils\n",
    "from tf_agents.trajectories import policy_step\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.trajectories import trajectory as trajectory_lib\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.typing import types\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set local runtime configurations\n",
    "\n",
    "\n",
    "def logging_info(*args):\n",
    "  logging.info(*args)\n",
    "  print(*args)\n",
    "\n",
    "data_path = \"/home/derek/sbsim/smart_control/configs/resources/sb1/\" #@param {type:\"string\"}\n",
    "metrics_path = \"/home/derek/sbsim/metrics/\" #@param {type:\"string\"}\n",
    "output_data_path = '/home/derek/sbsim/smart_control/PPO/' #@param {type:\"string\"}\n",
    "root_dir = \"/home/derek/sbsim/\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "# \n",
    "@gin.configurable\n",
    "def get_histogram_reducer():\n",
    "\n",
    "\n",
    "    reader = controller_reader.ProtoReader(data_path)\n",
    "\n",
    "    hr = histogram_reducer.HistogramReducer(\n",
    "        histogram_parameters_tuples=histogram_parameters_tuples,\n",
    "        reader=reader,\n",
    "        normalize_reduce=True,\n",
    "        )\n",
    "    return hr\n",
    "\n",
    "!mkdir -p $root_dir\n",
    "!mkdir -p $output_data_path\n",
    "!mkdir -p $metrics_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remap_filepath(filepath) -> str:\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plotting Utities\n",
    "reward_shift = 0\n",
    "reward_scale = 1.0\n",
    "person_productivity_hour = 300.0\n",
    "\n",
    "KELVIN_TO_CELSIUS = 273.15\n",
    "\n",
    "\n",
    "def render_env(env: environment.Environment):\n",
    "  \"\"\"Renders the environment.\"\"\"\n",
    "  building_layout = env.building._simulator._building._floor_plan\n",
    "\n",
    "  # create a renderer\n",
    "  renderer = building_renderer.BuildingRenderer(building_layout, 1)\n",
    "\n",
    "  # get the current temps to render\n",
    "  # this also is not ideal, since the temps are not fully exposed.\n",
    "  # V Ideally this should be a publicly accessable field\n",
    "  temps = env.building._simulator._building.temp\n",
    "\n",
    "  input_q = env.building._simulator._building.input_q\n",
    "\n",
    "  # render\n",
    "  vmin = 285\n",
    "  vmax = 305\n",
    "  image = renderer.render(\n",
    "      temps,\n",
    "      cmap='bwr',\n",
    "      vmin=vmin,\n",
    "      vmax=vmax,\n",
    "      colorbar=False,\n",
    "      input_q=input_q,\n",
    "      diff_range=0.5,\n",
    "      diff_size=1,\n",
    "  ).convert('RGB')\n",
    "  media.show_image(\n",
    "      image, title='Environment %s' % env.current_simulation_timestamp\n",
    "  )\n",
    "\n",
    "\n",
    "def get_energy_timeseries(reward_infos, time_zone: str) -> pd.DataFrame:\n",
    "  \"\"\"Returns a timeseries of energy rates.\"\"\"\n",
    "\n",
    "  start_times = []\n",
    "  end_times = []\n",
    "\n",
    "  device_ids = []\n",
    "  device_types = []\n",
    "  air_handler_blower_electrical_energy_rates = []\n",
    "  air_handler_air_conditioner_energy_rates = []\n",
    "  boiler_natural_gas_heating_energy_rates = []\n",
    "  boiler_pump_electrical_energy_rates = []\n",
    "\n",
    "  for reward_info in reward_infos:\n",
    "    end_timestamp = conversion_utils.proto_to_pandas_timestamp(\n",
    "        reward_info.end_timestamp\n",
    "    ).tz_convert(time_zone)\n",
    "    start_timestamp = end_timestamp - pd.Timedelta(300, unit='second')\n",
    "\n",
    "    for air_handler_id in reward_info.air_handler_reward_infos:\n",
    "      start_times.append(start_timestamp)\n",
    "      end_times.append(end_timestamp)\n",
    "\n",
    "      device_ids.append(air_handler_id)\n",
    "      device_types.append('air_handler')\n",
    "\n",
    "      air_handler_blower_electrical_energy_rates.append(\n",
    "          reward_info.air_handler_reward_infos[\n",
    "              air_handler_id\n",
    "          ].blower_electrical_energy_rate\n",
    "      )\n",
    "      air_handler_air_conditioner_energy_rates.append(\n",
    "          reward_info.air_handler_reward_infos[\n",
    "              air_handler_id\n",
    "          ].air_conditioning_electrical_energy_rate\n",
    "      )\n",
    "      boiler_natural_gas_heating_energy_rates.append(0)\n",
    "      boiler_pump_electrical_energy_rates.append(0)\n",
    "\n",
    "    for boiler_id in reward_info.boiler_reward_infos:\n",
    "      start_times.append(start_timestamp)\n",
    "      end_times.append(end_timestamp)\n",
    "\n",
    "      device_ids.append(boiler_id)\n",
    "      device_types.append('boiler')\n",
    "\n",
    "      air_handler_blower_electrical_energy_rates.append(0)\n",
    "      air_handler_air_conditioner_energy_rates.append(0)\n",
    "\n",
    "      boiler_natural_gas_heating_energy_rates.append(\n",
    "          reward_info.boiler_reward_infos[\n",
    "              boiler_id\n",
    "          ].natural_gas_heating_energy_rate\n",
    "      )\n",
    "      boiler_pump_electrical_energy_rates.append(\n",
    "          reward_info.boiler_reward_infos[boiler_id].pump_electrical_energy_rate\n",
    "      )\n",
    "\n",
    "  df_map = {\n",
    "      'start_time': start_times,\n",
    "      'end_time': end_times,\n",
    "      'device_id': device_ids,\n",
    "      'device_type': device_types,\n",
    "      'air_handler_blower_electrical_energy_rate': (\n",
    "          air_handler_blower_electrical_energy_rates\n",
    "      ),\n",
    "      'air_handler_air_conditioner_energy_rate': (\n",
    "          air_handler_air_conditioner_energy_rates\n",
    "      ),\n",
    "      'boiler_natural_gas_heating_energy_rate': (\n",
    "          boiler_natural_gas_heating_energy_rates\n",
    "      ),\n",
    "      'boiler_pump_electrical_energy_rate': boiler_pump_electrical_energy_rates,\n",
    "  }\n",
    "  df = pd.DataFrame(df_map).sort_values('start_time')\n",
    "  return df\n",
    "\n",
    "\n",
    "def get_outside_air_temperature_timeseries(\n",
    "    observation_responses,\n",
    "    time_zone: str,\n",
    ") -> pd.Series:\n",
    "  \"\"\"Returns a timeseries of outside air temperature.\"\"\"\n",
    "  temps = []\n",
    "  for i in range(len(observation_responses)):\n",
    "    temp = [\n",
    "        (\n",
    "            conversion_utils.proto_to_pandas_timestamp(\n",
    "                sor.timestamp\n",
    "            ).tz_convert(time_zone)\n",
    "            - pd.Timedelta(300, unit='second'),\n",
    "            sor.continuous_value,\n",
    "        )\n",
    "        for sor in observation_responses[i].single_observation_responses\n",
    "        if sor.single_observation_request.measurement_name\n",
    "        == 'outside_air_temperature_sensor'\n",
    "    ][0]\n",
    "    temps.append(temp)\n",
    "\n",
    "  res = list(zip(*temps))\n",
    "  return pd.Series(res[1], index=res[0]).sort_index()\n",
    "\n",
    "\n",
    "def get_reward_timeseries(\n",
    "    reward_infos,\n",
    "    reward_responses,\n",
    "    time_zone: str,\n",
    ") -> pd.DataFrame:\n",
    "  \"\"\"Returns a timeseries of reward values.\"\"\"\n",
    "  cols = [\n",
    "      'agent_reward_value',\n",
    "      'electricity_energy_cost',\n",
    "      'carbon_emitted',\n",
    "      'occupancy',\n",
    "  ]\n",
    "  df = pd.DataFrame(columns=cols)\n",
    "\n",
    "  for i in range(min(len(reward_responses), len(reward_infos))):\n",
    "    step_start_timestamp = conversion_utils.proto_to_pandas_timestamp(\n",
    "        reward_infos[i].start_timestamp\n",
    "    ).tz_convert(time_zone)\n",
    "    step_end_timestamp = conversion_utils.proto_to_pandas_timestamp(\n",
    "        reward_infos[i].end_timestamp\n",
    "    ).tz_convert(time_zone)\n",
    "    delta_time_sec = (step_end_timestamp - step_start_timestamp).total_seconds()\n",
    "    occupancy = np.sum([\n",
    "        reward_infos[i].zone_reward_infos[zone_id].average_occupancy\n",
    "        for zone_id in reward_infos[i].zone_reward_infos\n",
    "    ])\n",
    "\n",
    "    df.loc[\n",
    "        conversion_utils.proto_to_pandas_timestamp(\n",
    "            reward_infos[i].start_timestamp\n",
    "        ).tz_convert(time_zone)\n",
    "    ] = [\n",
    "        reward_responses[i].agent_reward_value,\n",
    "        reward_responses[i].electricity_energy_cost,\n",
    "        reward_responses[i].carbon_emitted,\n",
    "        occupancy,\n",
    "    ]\n",
    "\n",
    "  df = df.sort_index()\n",
    "  df['cumulative_reward'] = df['agent_reward_value'].cumsum()\n",
    "  logging_info('Cumulative reward: %4.2f' % df.iloc[-1]['cumulative_reward'])\n",
    "  return df\n",
    "\n",
    "\n",
    "def format_plot(\n",
    "    ax1, xlabel: str, start_time: int, end_time: int, time_zone: str\n",
    "):\n",
    "  \"\"\"Formats a plot with common attributes.\"\"\"\n",
    "  ax1.set_facecolor('black')\n",
    "  ax1.xaxis.tick_top()\n",
    "  ax1.tick_params(axis='x', labelsize=12)\n",
    "  ax1.tick_params(axis='y', labelsize=12)\n",
    "  ax1.xaxis.set_major_formatter(\n",
    "      mdates.DateFormatter('%a %m/%d %H:%M', tz=pytz.timezone(time_zone))\n",
    "  )\n",
    "  ax1.grid(color='gray', linestyle='-', linewidth=1.0)\n",
    "  ax1.set_ylabel(xlabel, color='blue', fontsize=12)\n",
    "  ax1.set_xlim(left=start_time, right=end_time)\n",
    "  ax1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "  ax1.legend(prop={'size': 10})\n",
    "\n",
    "\n",
    "def plot_occupancy_timeline(\n",
    "    ax1, reward_timeseries: pd.DataFrame, time_zone: str\n",
    "):\n",
    "  local_times = [ts.tz_convert(time_zone) for ts in reward_timeseries.index]\n",
    "  ax1.plot(\n",
    "      local_times,\n",
    "      reward_timeseries['occupancy'],\n",
    "      color='cyan',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=2,\n",
    "      linestyle='-',\n",
    "      label='Num Occupants',\n",
    "  )\n",
    "  format_plot(\n",
    "      ax1,\n",
    "      'Occupancy',\n",
    "      reward_timeseries.index.min(),\n",
    "      reward_timeseries.index.max(),\n",
    "      time_zone,\n",
    "  )\n",
    "\n",
    "\n",
    "def plot_energy_cost_timeline(\n",
    "    ax1,\n",
    "    reward_timeseries: pd.DataFrame,\n",
    "    time_zone: str,\n",
    "    cumulative: bool = False,\n",
    "):\n",
    "  local_times = [ts.tz_convert(time_zone) for ts in reward_timeseries.index]\n",
    "  if cumulative:\n",
    "    feature_timeseries_cost = reward_timeseries[\n",
    "        'electricity_energy_cost'\n",
    "    ].cumsum()\n",
    "  else:\n",
    "    feature_timeseries_cost = reward_timeseries['electricity_energy_cost']\n",
    "  ax1.plot(\n",
    "      local_times,\n",
    "      feature_timeseries_cost,\n",
    "      color='magenta',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=2,\n",
    "      linestyle='-',\n",
    "      label='Electricity',\n",
    "  )\n",
    "\n",
    "  format_plot(\n",
    "      ax1,\n",
    "      'Energy Cost [$]',\n",
    "      reward_timeseries.index.min(),\n",
    "      reward_timeseries.index.max(),\n",
    "      time_zone,\n",
    "  )\n",
    "\n",
    "\n",
    "def plot_reward_timeline(ax1, reward_timeseries, time_zone):\n",
    "\n",
    "  local_times = [ts.tz_convert(time_zone) for ts in reward_timeseries.index]\n",
    "\n",
    "  ax1.plot(\n",
    "      local_times,\n",
    "      reward_timeseries['cumulative_reward'],\n",
    "      color='royalblue',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=6,\n",
    "      linestyle='-',\n",
    "      label='reward',\n",
    "  )\n",
    "  format_plot(\n",
    "      ax1,\n",
    "      'Agent Reward',\n",
    "      reward_timeseries.index.min(),\n",
    "      reward_timeseries.index.max(),\n",
    "      time_zone,\n",
    "  )\n",
    "\n",
    "\n",
    "def plot_energy_timeline(ax1, energy_timeseries, time_zone, cumulative=False):\n",
    "\n",
    "  def _to_kwh(\n",
    "      energy_rate: float,\n",
    "      step_interval: pd.Timedelta = pd.Timedelta(5, unit='minute'),\n",
    "  ) -> float:\n",
    "    kw_power = energy_rate / 1000.0\n",
    "    hwh_power = kw_power * step_interval / pd.Timedelta(1, unit='hour')\n",
    "    return hwh_power.cumsum()\n",
    "\n",
    "  timeseries = energy_timeseries[\n",
    "      energy_timeseries['device_type'] == 'air_handler'\n",
    "  ]\n",
    "\n",
    "  if cumulative:\n",
    "    feature_timeseries_ac = _to_kwh(\n",
    "        timeseries['air_handler_air_conditioner_energy_rate']\n",
    "    )\n",
    "    feature_timeseries_blower = _to_kwh(\n",
    "        timeseries['air_handler_blower_electrical_energy_rate']\n",
    "    )\n",
    "  else:\n",
    "    feature_timeseries_ac = (\n",
    "        timeseries['air_handler_air_conditioner_energy_rate'] / 1000.0\n",
    "    )\n",
    "    feature_timeseries_blower = (\n",
    "        timeseries['air_handler_blower_electrical_energy_rate'] / 1000.0\n",
    "    )\n",
    "\n",
    "  ax1.plot(\n",
    "      timeseries['start_time'],\n",
    "      feature_timeseries_ac,\n",
    "      color='magenta',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=4,\n",
    "      linestyle='-',\n",
    "      label='AHU Electricity',\n",
    "  )\n",
    "  ax1.plot(\n",
    "      timeseries['start_time'],\n",
    "      feature_timeseries_blower,\n",
    "      color='magenta',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=4,\n",
    "      linestyle='--',\n",
    "      label='FAN Electricity',\n",
    "  )\n",
    "\n",
    "  timeseries = energy_timeseries[energy_timeseries['device_type'] == 'boiler']\n",
    "  if cumulative:\n",
    "    feature_timeseries_gas = _to_kwh(\n",
    "        timeseries['boiler_natural_gas_heating_energy_rate']\n",
    "    )\n",
    "    feature_timeseries_pump = _to_kwh(\n",
    "        timeseries['boiler_pump_electrical_energy_rate']\n",
    "    )\n",
    "  else:\n",
    "    feature_timeseries_gas = (\n",
    "        timeseries['boiler_natural_gas_heating_energy_rate'] / 1000.0\n",
    "    )\n",
    "    feature_timeseries_pump = (\n",
    "        timeseries['boiler_pump_electrical_energy_rate'] / 1000.0\n",
    "    )\n",
    "\n",
    "  ax1.plot(\n",
    "      timeseries['start_time'],\n",
    "      feature_timeseries_gas,\n",
    "      color='lime',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=4,\n",
    "      linestyle='-',\n",
    "      label='BLR Gas',\n",
    "  )\n",
    "  ax1.plot(\n",
    "      timeseries['start_time'],\n",
    "      feature_timeseries_pump,\n",
    "      color='lime',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=4,\n",
    "      linestyle='--',\n",
    "      label='Pump Electricity',\n",
    "  )\n",
    "\n",
    "  if cumulative:\n",
    "    label = 'HVAC Energy Consumption [kWh]'\n",
    "  else:\n",
    "    label = 'HVAC Power Consumption [kW]'\n",
    "\n",
    "  format_plot(\n",
    "      ax1,\n",
    "      label,\n",
    "      timeseries['start_time'].min(),\n",
    "      timeseries['end_time'].max(),\n",
    "      time_zone,\n",
    "  )\n",
    "\n",
    "\n",
    "def plot_carbon_timeline(ax1, reward_timeseries, time_zone, cumulative=False):\n",
    "  \"\"\"Plots carbon-emission timeline.\"\"\"\n",
    "\n",
    "  if cumulative:\n",
    "    feature_timeseries_carbon = reward_timeseries['carbon_emitted'].cumsum()\n",
    "  else:\n",
    "    feature_timeseries_carbon = reward_timeseries['carbon_emitted']\n",
    "  ax1.plot(\n",
    "      reward_timeseries.index,\n",
    "      feature_timeseries_carbon,\n",
    "      color='white',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=4,\n",
    "      linestyle='-',\n",
    "      label='Carbon',\n",
    "  )\n",
    "  format_plot(\n",
    "      ax1,\n",
    "      'Carbon emission [kg]',\n",
    "      reward_timeseries.index.min(),\n",
    "      reward_timeseries.index.max(),\n",
    "      time_zone,\n",
    "  )\n",
    "\n",
    "\n",
    "def get_zone_timeseries(reward_infos, time_zone):\n",
    "  \"\"\"Converts reward infos to a timeseries dataframe.\"\"\"\n",
    "\n",
    "  start_times = []\n",
    "  end_times = []\n",
    "  zones = []\n",
    "  heating_setpoints = []\n",
    "  cooling_setpoints = []\n",
    "  zone_air_temperatures = []\n",
    "  air_flow_rate_setpoints = []\n",
    "  air_flow_rates = []\n",
    "  average_occupancies = []\n",
    "\n",
    "  for reward_info in reward_infos:\n",
    "    start_timestamp = conversion_utils.proto_to_pandas_timestamp(\n",
    "        reward_info.end_timestamp\n",
    "    ).tz_convert(time_zone) - pd.Timedelta(300, unit='second')\n",
    "    end_timestamp = conversion_utils.proto_to_pandas_timestamp(\n",
    "        reward_info.end_timestamp\n",
    "    ).tz_convert(time_zone)\n",
    "\n",
    "    for zone_id in reward_info.zone_reward_infos:\n",
    "      zones.append(zone_id)\n",
    "      start_times.append(start_timestamp)\n",
    "      end_times.append(end_timestamp)\n",
    "\n",
    "      heating_setpoints.append(\n",
    "          reward_info.zone_reward_infos[zone_id].heating_setpoint_temperature\n",
    "      )\n",
    "      cooling_setpoints.append(\n",
    "          reward_info.zone_reward_infos[zone_id].cooling_setpoint_temperature\n",
    "      )\n",
    "\n",
    "      zone_air_temperatures.append(\n",
    "          reward_info.zone_reward_infos[zone_id].zone_air_temperature\n",
    "      )\n",
    "      air_flow_rate_setpoints.append(\n",
    "          reward_info.zone_reward_infos[zone_id].air_flow_rate_setpoint\n",
    "      )\n",
    "      air_flow_rates.append(\n",
    "          reward_info.zone_reward_infos[zone_id].air_flow_rate\n",
    "      )\n",
    "      average_occupancies.append(\n",
    "          reward_info.zone_reward_infos[zone_id].average_occupancy\n",
    "      )\n",
    "\n",
    "  df_map = {\n",
    "      'start_time': start_times,\n",
    "      'end_time': end_times,\n",
    "      'zone': zones,\n",
    "      'heating_setpoint_temperature': heating_setpoints,\n",
    "      'cooling_setpoint_temperature': cooling_setpoints,\n",
    "      'zone_air_temperature': zone_air_temperatures,\n",
    "      'air_flow_rate_setpoint': air_flow_rate_setpoints,\n",
    "      'air_flow_rate': air_flow_rates,\n",
    "      'average_occupancy': average_occupancies,\n",
    "  }\n",
    "  return pd.DataFrame(df_map).sort_values('start_time')\n",
    "\n",
    "\n",
    "def get_action_timeseries(action_responses):\n",
    "  \"\"\"Converts action responses to a dataframe.\"\"\"\n",
    "  timestamps = []\n",
    "  device_ids = []\n",
    "  setpoint_names = []\n",
    "  setpoint_values = []\n",
    "  response_types = []\n",
    "  for action_response in action_responses:\n",
    "\n",
    "    timestamp = conversion_utils.proto_to_pandas_timestamp(\n",
    "        action_response.timestamp\n",
    "    )\n",
    "    for single_action_response in action_response.single_action_responses:\n",
    "      device_id = single_action_response.request.device_id\n",
    "      setpoint_name = single_action_response.request.setpoint_name\n",
    "      setpoint_value = single_action_response.request.continuous_value\n",
    "      response_type = single_action_response.response_type\n",
    "\n",
    "      timestamps.append(timestamp)\n",
    "      device_ids.append(device_id)\n",
    "      setpoint_names.append(setpoint_name)\n",
    "      setpoint_values.append(setpoint_value)\n",
    "      response_types.append(response_type)\n",
    "\n",
    "  return pd.DataFrame({\n",
    "      'timestamp': timestamps,\n",
    "      'device_id': device_ids,\n",
    "      'setpoint_name': setpoint_names,\n",
    "      'setpoint_value': setpoint_values,\n",
    "      'response_type': response_types,\n",
    "  })\n",
    "\n",
    "\n",
    "def plot_action_timeline(ax1, action_timeseries, action_tuple, time_zone):\n",
    "  \"\"\"Plots action timeline.\"\"\"\n",
    "\n",
    "  single_action_timeseries = action_timeseries[\n",
    "      (action_timeseries['device_id'] == action_tuple[0])\n",
    "      & (action_timeseries['setpoint_name'] == action_tuple[1])\n",
    "  ]\n",
    "  single_action_timeseries = single_action_timeseries.sort_values(\n",
    "      by='timestamp'\n",
    "  )\n",
    "\n",
    "  if action_tuple[1] in [\n",
    "      'supply_water_setpoint',\n",
    "      'supply_air_heating_temperature_setpoint',\n",
    "  ]:\n",
    "    single_action_timeseries['setpoint_value'] = (\n",
    "        single_action_timeseries['setpoint_value'] - KELVIN_TO_CELSIUS\n",
    "    )\n",
    "\n",
    "  ax1.plot(\n",
    "      single_action_timeseries['timestamp'],\n",
    "      single_action_timeseries['setpoint_value'],\n",
    "      color='lime',\n",
    "      marker=None,\n",
    "      alpha=1,\n",
    "      lw=4,\n",
    "      linestyle='-',\n",
    "      label=action_tuple[1],\n",
    "  )\n",
    "  title = '%s %s' % (action_tuple[0], action_tuple[1])\n",
    "  format_plot(\n",
    "      ax1,\n",
    "      'Action',\n",
    "      single_action_timeseries['timestamp'].min(),\n",
    "      single_action_timeseries['timestamp'].max(),\n",
    "      time_zone,\n",
    "  )\n",
    "\n",
    "\n",
    "def get_outside_air_temperature_timeseries(observation_responses, time_zone):\n",
    "  temps = []\n",
    "  for i in range(len(observation_responses)):\n",
    "    temp = [\n",
    "        (\n",
    "            conversion_utils.proto_to_pandas_timestamp(\n",
    "                sor.timestamp\n",
    "            ).tz_convert(time_zone),\n",
    "            sor.continuous_value,\n",
    "        )\n",
    "        for sor in observation_responses[i].single_observation_responses\n",
    "        if sor.single_observation_request.measurement_name\n",
    "        == 'outside_air_temperature_sensor'\n",
    "    ][0]\n",
    "    temps.append(temp)\n",
    "\n",
    "  res = list(zip(*temps))\n",
    "  return pd.Series(res[1], index=res[0]).sort_index()\n",
    "\n",
    "\n",
    "def plot_temperature_timeline(\n",
    "    ax1, zone_timeseries, outside_air_temperature_timeseries, time_zone\n",
    "):\n",
    "  zone_temps = pd.pivot_table(\n",
    "      zone_timeseries,\n",
    "      index=zone_timeseries['start_time'],\n",
    "      columns='zone',\n",
    "      values='zone_air_temperature',\n",
    "  ).sort_index()\n",
    "  zone_temps.quantile(q=0.25, axis=1)\n",
    "  zone_temp_stats = pd.DataFrame({\n",
    "      'min_temp': zone_temps.min(axis=1),\n",
    "      'q25_temp': zone_temps.quantile(q=0.25, axis=1),\n",
    "      'median_temp': zone_temps.median(axis=1),\n",
    "      'q75_temp': zone_temps.quantile(q=0.75, axis=1),\n",
    "      'max_temp': zone_temps.max(axis=1),\n",
    "  })\n",
    "\n",
    "  zone_heating_setpoints = (\n",
    "      pd.pivot_table(\n",
    "          zone_timeseries,\n",
    "          index=zone_timeseries['start_time'],\n",
    "          columns='zone',\n",
    "          values='heating_setpoint_temperature',\n",
    "      )\n",
    "      .sort_index()\n",
    "      .min(axis=1)\n",
    "  )\n",
    "  zone_cooling_setpoints = (\n",
    "      pd.pivot_table(\n",
    "          zone_timeseries,\n",
    "          index=zone_timeseries['start_time'],\n",
    "          columns='zone',\n",
    "          values='cooling_setpoint_temperature',\n",
    "      )\n",
    "      .sort_index()\n",
    "      .max(axis=1)\n",
    "  )\n",
    "\n",
    "  ax1.plot(\n",
    "      zone_cooling_setpoints.index,\n",
    "      zone_cooling_setpoints - KELVIN_TO_CELSIUS,\n",
    "      color='yellow',\n",
    "      lw=1,\n",
    "  )\n",
    "  ax1.plot(\n",
    "      zone_cooling_setpoints.index,\n",
    "      zone_heating_setpoints - KELVIN_TO_CELSIUS,\n",
    "      color='yellow',\n",
    "      lw=1,\n",
    "  )\n",
    "\n",
    "  ax1.fill_between(\n",
    "      zone_temp_stats.index,\n",
    "      zone_temp_stats['min_temp'] - KELVIN_TO_CELSIUS,\n",
    "      zone_temp_stats['max_temp'] - KELVIN_TO_CELSIUS,\n",
    "      facecolor='green',\n",
    "      alpha=0.8,\n",
    "  )\n",
    "  ax1.fill_between(\n",
    "      zone_temp_stats.index,\n",
    "      zone_temp_stats['q25_temp'] - KELVIN_TO_CELSIUS,\n",
    "      zone_temp_stats['q75_temp'] - KELVIN_TO_CELSIUS,\n",
    "      facecolor='green',\n",
    "      alpha=0.8,\n",
    "  )\n",
    "  ax1.plot(\n",
    "      zone_temp_stats.index,\n",
    "      zone_temp_stats['median_temp'] - KELVIN_TO_CELSIUS,\n",
    "      color='white',\n",
    "      lw=3,\n",
    "      alpha=1.0,\n",
    "  )\n",
    "  ax1.plot(\n",
    "      outside_air_temperature_timeseries.index,\n",
    "      outside_air_temperature_timeseries - KELVIN_TO_CELSIUS,\n",
    "      color='magenta',\n",
    "      lw=3,\n",
    "      alpha=1.0,\n",
    "  )\n",
    "  format_plot(\n",
    "      ax1,\n",
    "      'Temperature [C]',\n",
    "      zone_temp_stats.index.min(),\n",
    "      zone_temp_stats.index.max(),\n",
    "      time_zone,\n",
    "  )\n",
    "\n",
    "\n",
    "def plot_timeseries_charts(reader, time_zone):\n",
    "    \"\"\"Plots timeseries charts.\"\"\"\n",
    "    observation_responses = reader.read_observation_responses(\n",
    "        pd.Timestamp.min, pd.Timestamp.max\n",
    "    )\n",
    "    action_responses = reader.read_action_responses(\n",
    "        pd.Timestamp.min, pd.Timestamp.max\n",
    "    )\n",
    "    reward_infos = reader.read_reward_infos(pd.Timestamp.min, pd.Timestamp.max)\n",
    "    reward_responses = reader.read_reward_responses(\n",
    "        pd.Timestamp.min, pd.Timestamp.max\n",
    "    )\n",
    "\n",
    "    if len(reward_infos) == 0 or len(reward_responses) == 0:\n",
    "        return\n",
    "\n",
    "    action_timeseries = get_action_timeseries(action_responses)\n",
    "    action_tuples = list(\n",
    "        set([\n",
    "            (row['device_id'], row['setpoint_name'])\n",
    "            for _, row in action_timeseries.iterrows()\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    reward_timeseries = get_reward_timeseries(\n",
    "        reward_infos, reward_responses, time_zone\n",
    "    ).sort_index()\n",
    "    outside_air_temperature_timeseries = get_outside_air_temperature_timeseries(\n",
    "        observation_responses, time_zone\n",
    "    )\n",
    "    zone_timeseries = get_zone_timeseries(reward_infos, time_zone)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=6 + len(action_tuples),\n",
    "        ncols=1,\n",
    "        gridspec_kw={\n",
    "            'height_ratios': [1, 1, 1, 1, 1, 1] + [1] * len(action_tuples)\n",
    "        },\n",
    "        squeeze=True,\n",
    "    )\n",
    "    fig.set_size_inches(24, 25)\n",
    "\n",
    "    energy_timeseries = get_energy_timeseries(reward_infos, time_zone)\n",
    "    plot_reward_timeline(axes[0], reward_timeseries, time_zone)\n",
    "    plot_energy_timeline(axes[1], energy_timeseries, time_zone, cumulative=True)\n",
    "    plot_energy_cost_timeline(\n",
    "        axes[2], reward_timeseries, time_zone, cumulative=True\n",
    "    )\n",
    "    plot_carbon_timeline(axes[3], reward_timeseries, time_zone, cumulative=True)\n",
    "    plot_occupancy_timeline(axes[4], reward_timeseries, time_zone)\n",
    "    plot_temperature_timeline(\n",
    "        axes[5], zone_timeseries, outside_air_temperature_timeseries, time_zone\n",
    "    )\n",
    "\n",
    "    for i, action_tuple in enumerate(action_tuples):\n",
    "        plot_action_timeline(\n",
    "            axes[6 + i], action_timeseries, action_tuple, time_zone\n",
    "        )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up the environment\n",
    "\n",
    "In this section we load up the Smart Buildings simulator environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Utils for importing the environment.\n",
    "\n",
    "def load_environment(gin_config_file: str):\n",
    "  \"\"\"Returns an Environment from a config file.\"\"\"\n",
    "  # Global definition is required by Gin library to instantiate Environment.\n",
    "  global environment  # pylint: disable=global-variable-not-assigned\n",
    "  with gin.unlock_config():\n",
    "    gin.parse_config_file(gin_config_file)\n",
    "    return environment.Environment()  # pylint: disable=no-value-for-parameter\n",
    "\n",
    "\n",
    "def get_latest_episode_reader(\n",
    "    metrics_path: str,\n",
    ") -> controller_reader.ProtoReader:\n",
    "\n",
    "  episode_infos = controller_reader.get_episode_data(metrics_path).sort_index()\n",
    "  selected_episode = episode_infos.index[-1]\n",
    "  episode_path = os.path.join(metrics_path, selected_episode)\n",
    "  reader = controller_reader.ProtoReader(episode_path)\n",
    "  return reader\n",
    "\n",
    "@gin.configurable\n",
    "def get_histogram_path():\n",
    "  return data_path\n",
    "\n",
    "\n",
    "@gin.configurable\n",
    "def get_reset_temp_values():\n",
    "  reset_temps_filepath = remap_filepath(\n",
    "      os.path.join(data_path, \"reset_temps.npy\")\n",
    "  )\n",
    "\n",
    "  return np.load(reset_temps_filepath)\n",
    "\n",
    "\n",
    "@gin.configurable\n",
    "def get_zone_path():\n",
    "  return remap_filepath(\n",
    "      os.path.join(data_path, \"double_resolution_zone_1_2.npy\")\n",
    "  )\n",
    "\n",
    "\n",
    "@gin.configurable\n",
    "def get_metrics_path():\n",
    "  return os.path.join(metrics_path, \"metrics\")\n",
    "\n",
    "\n",
    "@gin.configurable\n",
    "def get_weather_path():\n",
    "  return remap_filepath(\n",
    "      os.path.join(\n",
    "          data_path, \"local_weather_moffett_field_20230701_20231122.csv\"\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/derek/sbsim/smart_control/configs/resources/sb1/sim_config.gin\n",
      "/home/derek/sbsim/smart_control/configs/resources/sb1/sim_config.gin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/sbsim/smart_control/simulator/building_utils.py:283: UserWarning: Connected components is showing that there are 4 or fewer\n",
      "     rooms in your building. You may have your 0's and 1's inverted in the\n",
      "     floor_plan. Remember that for the connectedComponents function,\n",
      "     0's must code for exterior space and exterior or interior walls,\n",
      "     and 1's must code for interior space.\n",
      "  warnings.warn(\"\"\"Connected components is showing that there are 4 or fewer\n",
      "2024-10-30 12:47:39.075569: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.182571: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.182887: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.200276: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.200533: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.200645: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.450844: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.451095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.451246: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-30 12:47:39.451357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22272 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:0e:00.0, compute capability: 8.9\n",
      "/home/derek/sbsim/smart_control/reward/electricity_energy_cost.py:147: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  np.array(carbon_emission_rates) / 1.0e6 / 3600.0\n",
      "/home/derek/sbsim/smart_control/reward/electricity_energy_cost.py:152: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  np.array(weekday_energy_prices)\n",
      "/home/derek/sbsim/smart_control/reward/electricity_energy_cost.py:159: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  np.array(weekend_energy_prices)\n",
      "/home/derek/sbsim/smart_control/simulator/building_utils.py:283: UserWarning: Connected components is showing that there are 4 or fewer\n",
      "     rooms in your building. You may have your 0's and 1's inverted in the\n",
      "     floor_plan. Remember that for the connectedComponents function,\n",
      "     0's must code for exterior space and exterior or interior walls,\n",
      "     and 1's must code for interior space.\n",
      "  warnings.warn(\"\"\"Connected components is showing that there are 4 or fewer\n",
      "/home/derek/sbsim/smart_control/reward/electricity_energy_cost.py:147: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  np.array(carbon_emission_rates) / 1.0e6 / 3600.0\n",
      "/home/derek/sbsim/smart_control/reward/electricity_energy_cost.py:152: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  np.array(weekday_energy_prices)\n",
      "/home/derek/sbsim/smart_control/reward/electricity_energy_cost.py:159: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  np.array(weekend_energy_prices)\n"
     ]
    }
   ],
   "source": [
    "# @gin.configurable\n",
    "def to_timestamp(date_str: str) -> pd.Timestamp:\n",
    "  \"\"\"Utilty macro for gin config.\"\"\"\n",
    "  return pd.Timestamp(date_str)\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "def local_time(time_str: str) -> pd.Timedelta:\n",
    "  \"\"\"Utilty macro for gin config.\"\"\"\n",
    "  return pd.Timedelta(time_str)\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "def enumerate_zones(\n",
    "    n_building_x: int, n_building_y: int\n",
    ") -> Sequence[tuple[int, int]]:\n",
    "  \"\"\"Utilty macro for gin config.\"\"\"\n",
    "  zone_coordinates = []\n",
    "  for x in range(n_building_x):\n",
    "    for y in range(n_building_y):\n",
    "      zone_coordinates.append((x, y))\n",
    "  return zone_coordinates\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "def set_observation_normalization_constants(\n",
    "    field_id: str, sample_mean: float, sample_variance: float\n",
    ") -> smart_control_normalization_pb2.ContinuousVariableInfo:\n",
    "  return smart_control_normalization_pb2.ContinuousVariableInfo(\n",
    "      id=field_id, sample_mean=sample_mean, sample_variance=sample_variance\n",
    "  )\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "def set_action_normalization_constants(\n",
    "    min_native_value,\n",
    "    max_native_value,\n",
    "    min_normalized_value,\n",
    "    max_normalized_value,\n",
    ") -> bounded_action_normalizer.BoundedActionNormalizer:\n",
    "  return bounded_action_normalizer.BoundedActionNormalizer(\n",
    "      min_native_value,\n",
    "      max_native_value,\n",
    "      min_normalized_value,\n",
    "      max_normalized_value,\n",
    "  )\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "def get_zones_from_config(\n",
    "    configuration_path: str,\n",
    ") -> Sequence[smart_control_building_pb2.ZoneInfo]:\n",
    "  \"\"\"Loads up the zones as a gin macro.\"\"\"\n",
    "  with gin.unlock_config():\n",
    "    reader = reader_lib_google.RecordIoReader(input_dir=configuration_path)\n",
    "    zone_infos = reader.read_zone_infos()\n",
    "    return zone_infos\n",
    "\n",
    "\n",
    "# @gin.configurable\n",
    "def get_devices_from_config(\n",
    "    configuration_path: str,\n",
    ") -> Sequence[smart_control_building_pb2.DeviceInfo]:\n",
    "  \"\"\"Loads up HVAC devices as a gin macro.\"\"\"\n",
    "  with gin.unlock_config():\n",
    "    reader = reader_lib_google.RecordIoReader(input_dir=configuration_path)\n",
    "    device_infos = reader.read_device_infos()\n",
    "    return device_infos\n",
    "\n",
    "# @title Load the environments\n",
    "\n",
    "histogram_parameters_tuples = (\n",
    "        ('zone_air_temperature_sensor',(285., 286., 287., 288, 289., 290., 291., 292., 293., 294., 295., 296., 297., 298., 299., 300.,301,302,303)),\n",
    "        ('supply_air_damper_percentage_command',(0.0, 0.2, 0.4, 0.6, 0.8, 1.0)),\n",
    "        ('supply_air_flowrate_setpoint',( 0., 0.05, .1, .2, .3, .4, .5,  .7,  .9)),\n",
    "    )\n",
    "\n",
    "time_zone = 'US/Pacific'\n",
    "collect_scenario_config = os.path.join(data_path, \"sim_config.gin\")\n",
    "print(collect_scenario_config)\n",
    "eval_scenario_config = os.path.join(data_path, \"sim_config.gin\")\n",
    "print(eval_scenario_config)\n",
    "\n",
    "\n",
    "collect_env = load_environment(collect_scenario_config)\n",
    "\n",
    "# For efficency, set metrics_path to None\n",
    "collect_env._metrics_path = None\n",
    "collect_env._occupancy_normalization_constant = 125.0\n",
    "\n",
    "# num_parallel_collect_envs = 4\n",
    "\n",
    "# def collect_env_creator():\n",
    "#     collect_env = load_environment(collect_scenario_config)\n",
    "#     # For efficency, set metrics_path to None\n",
    "#     collect_env._metrics_path = None\n",
    "#     collect_env._occupancy_normalization_constant = 125.0\n",
    "#     return collect_env\n",
    "  \n",
    "# collect_env_creators = [collect_env_creator] * num_parallel_collect_envs\n",
    "\n",
    "# parallel_collect_env = parallel_py_environment.ParallelPyEnvironment(collect_env_creators)\n",
    "\n",
    "# # convert to TF env\n",
    "# parallel_collect_env = tf_py_environment.TFPyEnvironment(parallel_collect_env)\n",
    "\n",
    "eval_env = load_environment(eval_scenario_config)\n",
    "# eval_env._label += \"_eval\"\n",
    "eval_env._metrics_path = metrics_path\n",
    "eval_env._occupancy_normalization_constant = 125.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set the RL Agent's parameters\n",
    "\n",
    "# Actor network fully connected layers.\n",
    "actor_fc_layers = (256, 256)\n",
    "\n",
    "# Value network observation fully connected layers.\n",
    "value_fc_layers = (256, 128)\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "actor_learning_rate = 3e-4\n",
    "critic_learning_rate = 3e-4\n",
    "alpha_learning_rate = 3e-4\n",
    "gamma = 0.99\n",
    "target_update_tau= 0.005\n",
    "target_update_period= 1\n",
    "reward_scale_factor = 1.0\n",
    "\n",
    "# Replay params\n",
    "replay_capacity = 1000000\n",
    "debug_summaries = True\n",
    "summarize_grads_and_vars = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 12:48:12.396162: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "/home/derek/sbsim/.venv/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer Orthogonal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "observation_tensor_spec, action_tensor_spec, time_step_tensor_spec = spec_utils.get_tensor_specs(\n",
    "    eval_env\n",
    ")\n",
    "\n",
    "# tf_ppo_actor_net = ppo_actor_network.PPOActorNetwork()\n",
    "# actor_net = tf_ppo_actor_net.create_sequential_actor_net(\n",
    "#     actor_fc_layers, action_tensor_spec, 85\n",
    "# )\n",
    "# can overload PPOActorNetwork with kernel_initializer='glorot_uniform' \n",
    "\n",
    "# actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "#     observation_tensor_spec,\n",
    "#     action_tensor_spec,\n",
    "#     fc_layer_params=actor_fc_layers,\n",
    "#     activation_fn=tf.keras.activations.tanh,\n",
    "# )\n",
    "\n",
    "\n",
    "from PPO_actor_net import PPOActorNetwork\n",
    "tf_ppo_actor_net = PPOActorNetwork()\n",
    "actor_net = tf_ppo_actor_net.create_sequential_actor_net(\n",
    "    actor_fc_layers, action_tensor_spec, 85\n",
    ")\n",
    "\n",
    "# actor_net = ppo_actor_network.PPOActorNetwork().create_sequential_actor_net(\n",
    "#     fc_layer_units=actor_fc_layers,\n",
    "#     action_tensor_spec=action_tensor_spec,\n",
    "#     seed=85\n",
    "# )\n",
    "\n",
    "\n",
    "value_net = value_network.ValueNetwork(\n",
    "    input_tensor_spec=observation_tensor_spec,\n",
    "    fc_layer_params=value_fc_layers,\n",
    "    activation_fn=tf.keras.activations.relu\n",
    ")\n",
    "\n",
    "\n",
    "# from ppo_clip_agent_clipped_action import PPOClipAgent\n",
    "\n",
    "train_step = train_utils.create_train_step()\n",
    "agent = ppo_clip_agent.PPOClipAgent(\n",
    "    time_step_spec=time_step_tensor_spec,\n",
    "    action_spec=action_tensor_spec,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=actor_learning_rate),\n",
    "    actor_net=actor_net,\n",
    "    value_net=value_net,\n",
    "    importance_ratio_clipping=0.2,       # Example hyperparameter\n",
    "    lambda_value=0.95,\n",
    "    discount_factor=0.99,\n",
    "    entropy_regularization=0.01,\n",
    "    value_pred_loss_coef=0.5,\n",
    "    num_epochs=25,\n",
    "    debug_summaries=debug_summaries,\n",
    "    summarize_grads_and_vars=summarize_grads_and_vars,\n",
    "    train_step_counter=train_step,\n",
    ")\n",
    "agent.collect_policy._clip=True # change clip parameter from TFPolicy parent class to clip action tensor\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set up the replay buffer\n",
    "replay_capacity = 1000000\n",
    "table_name = 'uniform_table'\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_capacity,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    ")\n",
    "\n",
    "reverb_checkpoint_dir = output_data_path + \"/reverb_checkpoint\"\n",
    "reverb_port = None\n",
    "print('reverb_checkpoint_dir=%s' %reverb_checkpoint_dir)\n",
    "reverb_checkpointer = reverb.platform.checkpointers_lib.DefaultCheckpointer(\n",
    "    path=reverb_checkpoint_dir\n",
    ")\n",
    "\n",
    "reverb_server = reverb.Server(\n",
    "    [table], port=reverb_port, checkpointer=reverb_checkpointer\n",
    ")\n",
    "\n",
    "logging_info('reverb_server_port=%d' %reverb_server.port)\n",
    "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    sequence_length=2,\n",
    "    table_name=table_name,\n",
    "    local_server=reverb_server,\n",
    ")\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "    reverb_replay.py_client, table_name, sequence_length=2, stride_length=1\n",
    ")\n",
    "print('num_frames in replay buffer=%d' %reverb_replay.num_frames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    batch_size=1,\n",
    "    max_length=1000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Access the eval and collect policies\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Observers\n",
    "class RenderAndPlotObserver:\n",
    "  \"\"\"Renders and plots the environment.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      render_interval_steps: int = 10,\n",
    "      environment=None,\n",
    "  ):\n",
    "    self._counter = 0\n",
    "    self._render_interval_steps = render_interval_steps\n",
    "    self._environment = environment\n",
    "    self._cumulative_reward = 0.0\n",
    "\n",
    "    self._start_time = None\n",
    "    if self._environment is not None:\n",
    "      self._num_timesteps_in_episode = (\n",
    "          self._environment._num_timesteps_in_episode\n",
    "      )\n",
    "      self._environment._end_timestamp\n",
    "\n",
    "  def __call__(self, trajectory: trajectory_lib.Trajectory) -> None:\n",
    "    reward = trajectory.reward\n",
    "    self._cumulative_reward += reward\n",
    "    self._counter += 1\n",
    "    if self._start_time is None:\n",
    "      self._start_time = pd.Timestamp.now()\n",
    "\n",
    "    if self._counter % self._render_interval_steps == 0 and self._environment:\n",
    "\n",
    "      execution_time = pd.Timestamp.now() - self._start_time\n",
    "      mean_execution_time = execution_time.total_seconds() / self._counter\n",
    "\n",
    "      clear_output(wait=True)\n",
    "      if self._environment._metrics_path is not None:\n",
    "        reader = get_latest_episode_reader(self._environment._metrics_path)\n",
    "        plot_timeseries_charts(reader, time_zone)\n",
    "\n",
    "      render_env(self._environment)\n",
    "\n",
    "\n",
    "class PrintStatusObserver:\n",
    "  \"\"\"Prints status information.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self, status_interval_steps: int = 1, environment=None, replay_buffer=None\n",
    "  ):\n",
    "    self._counter = 0\n",
    "    self._status_interval_steps = status_interval_steps\n",
    "    self._environment = environment\n",
    "    self._cumulative_reward = 0.0\n",
    "    self._replay_buffer = replay_buffer\n",
    "\n",
    "    self._start_time = None\n",
    "    if self._environment is not None:\n",
    "      self._num_timesteps_in_episode = (\n",
    "          self._environment._num_timesteps_in_episode\n",
    "      )\n",
    "      self._environment._end_timestamp\n",
    "\n",
    "  def __call__(self, trajectory: trajectory_lib.Trajectory) -> None:\n",
    "\n",
    "    reward = trajectory.reward\n",
    "    self._cumulative_reward += reward\n",
    "    self._counter += 1\n",
    "    if self._start_time is None:\n",
    "      self._start_time = pd.Timestamp.now()\n",
    "\n",
    "    if self._counter % self._status_interval_steps == 0 and self._environment:\n",
    "\n",
    "      execution_time = pd.Timestamp.now() - self._start_time\n",
    "      mean_execution_time = execution_time.total_seconds() / self._counter\n",
    "\n",
    "      sim_time = self._environment.current_simulation_timestamp.tz_convert(\n",
    "          time_zone\n",
    "      )\n",
    "      percent_complete = int(\n",
    "          100.0 * (self._counter / self._num_timesteps_in_episode)\n",
    "      )\n",
    "\n",
    "      if self._replay_buffer is not None:\n",
    "        rb_size = self._replay_buffer.num_frames()\n",
    "        rb_string = \" Replay Buffer Size: %d\" % rb_size\n",
    "      else:\n",
    "        rb_string = \"\"\n",
    "\n",
    "      print(\n",
    "          \"Step %5d of %5d (%3d%%) Sim Time: %s Reward: %2.2f Cumulative\"\n",
    "          \" Reward: %8.2f Execution Time: %s Mean Execution Time: %3.2fs %s\"\n",
    "          % (\n",
    "              self._environment._step_count,\n",
    "              self._num_timesteps_in_episode,\n",
    "              percent_complete,\n",
    "              sim_time.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "              reward,\n",
    "              self._cumulative_reward,\n",
    "              execution_time,\n",
    "              mean_execution_time,\n",
    "              rb_string,\n",
    "          )\n",
    "      )\n",
    "\n",
    "\n",
    "collect_render_plot_observer = RenderAndPlotObserver(\n",
    "    render_interval_steps=144, environment=collect_env\n",
    ")\n",
    "collect_print_status_observer = PrintStatusObserver(\n",
    "    status_interval_steps=1,\n",
    "    environment=collect_env,\n",
    "    replay_buffer=replay_buffer,\n",
    ")\n",
    "eval_render_plot_observer = RenderAndPlotObserver(\n",
    "    render_interval_steps=144, environment=eval_env\n",
    ")\n",
    "eval_print_status_observer = PrintStatusObserver(\n",
    "    status_interval_steps=1, environment=eval_env, replay_buffer=replay_buffer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = reverb_replay.as_dataset(\n",
    "#     num_parallel_calls=3,\n",
    "#     sample_batch_size=batch_size,\n",
    "#     num_steps=2).prefetch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    single_deterministic_pass=True,\n",
    "    num_steps=2,\n",
    "    sample_batch_size=batch_size\n",
    ").prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policies will be saved to saved_model_dir: /home/derek/sbsim/policies\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "To be compatible with tf.function, Python functions must return zero or more Tensors or ExtensionTypes or None values; in compilation of <function PolicySaver.__init__.<locals>.polymorphic_action_fn at 0x78db94d0a050>, found return value of type BoundedTensorSpec, which is not a Tensor or ExtensionType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py:611\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m   str_values \u001b[38;5;241m=\u001b[39m [compat\u001b[38;5;241m.\u001b[39mas_bytes(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py:611\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m   str_values \u001b[38;5;241m=\u001b[39m [\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proto_values]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/compat.py:87\u001b[0m, in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected binary or unicode string, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m     88\u001b[0m                   (bytes_or_text,))\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got BoundedTensorSpec(shape=(2,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1046\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.convert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1046\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor_or_composite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:806\u001b[0m, in \u001b[0;36mconvert_to_tensor_or_composite\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given object to a `Tensor` or `CompositeTensor`.\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \n\u001b[1;32m    790\u001b[0m \u001b[38;5;124;03mIf `value` is a `CompositeTensor` it is returned unmodified. Otherwise, it\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m  ValueError: If `dtype` does not match the element type of `value`.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minternal_convert_to_tensor_or_composite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:842\u001b[0m, in \u001b[0;36minternal_convert_to_tensor_or_composite\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m      \u001b[49m\u001b[43maccepted_result_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtensor_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomposite_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompositeTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    334\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03mNote: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m  ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:286\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_broadcast\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:263\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    261\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n\u001b[1;32m    262\u001b[0m tensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mCopyFrom(\n\u001b[0;32m--> 263\u001b[0m     \u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_tensor_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    266\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py:613\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 613\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert elements of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to Tensor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider casting elements to a supported type. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/api_docs/python/tf/dtypes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor supported TF dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    617\u001b[0m tensor_proto\u001b[38;5;241m.\u001b[39mstring_val\u001b[38;5;241m.\u001b[39mextend(str_values)\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert elements of BoundedTensorSpec(shape=(2,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolicies will be saved to saved_model_dir: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39msaved_model_dir)\n\u001b[1;32m      8\u001b[0m env_step_metric \u001b[38;5;241m=\u001b[39m py_metrics\u001b[38;5;241m.\u001b[39mEnvironmentSteps()\n\u001b[1;32m      9\u001b[0m learning_triggers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 10\u001b[0m       \u001b[43mtriggers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPolicySavedModelTrigger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m          \u001b[49m\u001b[43msaved_model_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m          \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_save_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmetadata_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mtriggers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mENV_STEP_METADATA_KEY\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_step_metric\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     17\u001b[0m       triggers\u001b[38;5;241m.\u001b[39mStepPerSecondLogTrigger(train_step, interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     20\u001b[0m agent_learner \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mLearner(\n\u001b[1;32m     21\u001b[0m       root_dir,\n\u001b[1;32m     22\u001b[0m       train_step,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m       summary_interval\u001b[38;5;241m=\u001b[39mlearner_summary_interval,\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/train/triggers.py:135\u001b[0m, in \u001b[0;36mPolicySavedModelTrigger.__init__\u001b[0;34m(self, saved_model_dir, agent, train_step, interval, async_saving, metadata_metrics, start, extra_concrete_functions, batch_size, use_nest_path_signatures, save_greedy_policy, save_collect_policy, input_fn_and_spec)\u001b[0m\n\u001b[1;32m    132\u001b[0m savers \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_policy_saver, learner\u001b[38;5;241m.\u001b[39mRAW_POLICY_SAVED_MODEL_DIR)]\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_collect_policy:\n\u001b[0;32m--> 135\u001b[0m   collect_policy_saver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_saver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m      \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_nest_path_signatures\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m   savers\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    140\u001b[0m       (collect_policy_saver, learner\u001b[38;5;241m.\u001b[39mCOLLECT_POLICY_SAVED_MODEL_DIR)\n\u001b[1;32m    141\u001b[0m   )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_greedy_policy:\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/train/triggers.py:177\u001b[0m, in \u001b[0;36mPolicySavedModelTrigger._build_saver\u001b[0;34m(self, policy, batch_size, use_nest_path_signatures)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_saver\u001b[39m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    173\u001b[0m     policy: tf_policy\u001b[38;5;241m.\u001b[39mTFPolicy,\n\u001b[1;32m    174\u001b[0m     batch_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m     use_nest_path_signatures: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[policy_saver\u001b[38;5;241m.\u001b[39mPolicySaver, async_policy_saver\u001b[38;5;241m.\u001b[39mAsyncPolicySaver]:\n\u001b[0;32m--> 177\u001b[0m   saver \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPolicySaver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_nest_path_signatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nest_path_signatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_fn_and_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_fn_and_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_saving:\n\u001b[1;32m    186\u001b[0m     saver \u001b[38;5;241m=\u001b[39m async_policy_saver\u001b[38;5;241m.\u001b[39mAsyncPolicySaver(saver)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/policies/policy_saver.py:419\u001b[0m, in \u001b[0;36mPolicySaver.__init__\u001b[0;34m(self, policy, batch_size, use_nest_path_signatures, seed, train_step, input_fn_and_spec, metadata)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;129m@common\u001b[39m\u001b[38;5;241m.\u001b[39mfunction()\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolymorphic_action_fn\u001b[39m(\n\u001b[1;32m    415\u001b[0m     time_step, policy_state\u001b[38;5;241m=\u001b[39mbatched_policy_state_spec\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m action_fn(time_step, policy_state)\n\u001b[0;32m--> 419\u001b[0m \u001b[43mpolymorphic_action_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched_time_step_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched_policy_state_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m polymorphic_action_fn\u001b[38;5;241m.\u001b[39mget_concrete_function(\n\u001b[1;32m    424\u001b[0m     time_step\u001b[38;5;241m=\u001b[39mbatched_time_step_spec\n\u001b[1;32m    425\u001b[0m )\n\u001b[1;32m    427\u001b[0m \u001b[38;5;129m@common\u001b[39m\u001b[38;5;241m.\u001b[39mfunction()\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolymorphic_distribution_fn\u001b[39m(\n\u001b[1;32m    429\u001b[0m     time_step, policy_state\u001b[38;5;241m=\u001b[39mbatched_policy_state_spec\n\u001b[1;32m    430\u001b[0m ):\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1064\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n\u001b[0;32m-> 1064\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# flatten and unflatten func_args and func_kwargs to maintain parity\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# from flattening which sorts by key\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m func_args \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   1070\u001b[0m     func_args,\n\u001b[1;32m   1071\u001b[0m     nest\u001b[38;5;241m.\u001b[39mflatten(func_args, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   1072\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1048\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.convert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     x \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor_or_composite(x)\n\u001b[1;32m   1047\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m-> 1048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo be compatible with tf.function, Python functions \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust return zero or more Tensors or ExtensionTypes or None \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1051\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues; in compilation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(python_func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1052\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is not a Tensor or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1053\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtensionType.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_control_dependencies:\n\u001b[1;32m   1055\u001b[0m   x \u001b[38;5;241m=\u001b[39m deps_ctx\u001b[38;5;241m.\u001b[39mmark_as_return(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: To be compatible with tf.function, Python functions must return zero or more Tensors or ExtensionTypes or None values; in compilation of <function PolicySaver.__init__.<locals>.polymorphic_action_fn at 0x78db94d0a050>, found return value of type BoundedTensorSpec, which is not a Tensor or ExtensionType."
     ]
    }
   ],
   "source": [
    "# @title Define an Agent Learner\n",
    "policy_save_interval = 1 # Save the policy after every learning step.\n",
    "learner_summary_interval = 1 # Produce a summary of the critic, actor, and alpha losses after every gradient update step.\n",
    "experience_dataset_fn = lambda: dataset\n",
    "\n",
    "saved_model_dir = os.path.join(root_dir, learner.POLICY_SAVED_MODEL_DIR)\n",
    "print('Policies will be saved to saved_model_dir: %s' %saved_model_dir)\n",
    "env_step_metric = py_metrics.EnvironmentSteps()\n",
    "learning_triggers = [\n",
    "      triggers.PolicySavedModelTrigger(\n",
    "          saved_model_dir,\n",
    "          agent,\n",
    "          train_step,\n",
    "          interval=policy_save_interval,\n",
    "          metadata_metrics={triggers.ENV_STEP_METADATA_KEY: env_step_metric},\n",
    "      ),\n",
    "      triggers.StepPerSecondLogTrigger(train_step, interval=10),\n",
    "]\n",
    "\n",
    "agent_learner = learner.Learner(\n",
    "      root_dir,\n",
    "      train_step,\n",
    "      agent,\n",
    "      experience_dataset_fn,\n",
    "      triggers=learning_triggers,\n",
    "      strategy=None,\n",
    "      summary_interval=learner_summary_interval,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Collect Actor and Eval Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_greedy_policy = greedy_policy.GreedyPolicy(agent.policy)\n",
    "tf_greedy_policy = greedy_policy.GreedyPolicy(agent.policy)\n",
    "eval_greedy_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "    tf_greedy_policy, use_tf_function=True\n",
    ")\n",
    "\n",
    "tf_collect_policy = agent.collect_policy\n",
    "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "    tf_collect_policy, use_tf_function=True\n",
    ")\n",
    "\n",
    "collect_actor = actor.Actor(\n",
    "    collect_env,\n",
    "    collect_policy,\n",
    "    train_step,\n",
    "    episodes_per_run=1, # each iter collect through entire episode\n",
    "    metrics=actor.collect_metrics(1),\n",
    "    summary_dir=os.path.join(root_dir, learner.TRAIN_DIR),\n",
    "    summary_interval=1,\n",
    "    observers=[\n",
    "        replay_buffer.add_batch,\n",
    "        env_step_metric,\n",
    "        collect_print_status_observer,\n",
    "        collect_render_plot_observer,\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_actor = actor.Actor(\n",
    "    eval_env,\n",
    "    eval_greedy_policy,\n",
    "    train_step,\n",
    "    episodes_per_run=1,\n",
    "    metrics=actor.eval_metrics(1),\n",
    "    summary_dir=os.path.join(root_dir, 'eval'),\n",
    "    summary_interval=1,\n",
    "    observers=[replay_buffer.add_batch, eval_print_status_observer, eval_render_plot_observer],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.\n",
      "Training iteration:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining iteration: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28miter\u001b[39m)\n\u001b[1;32m      9\u001b[0m _ \u001b[38;5;241m=\u001b[39m collect_env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcollect_actor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m logging_info(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecuting \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m gradient updates.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m%\u001b[39mnum_gradient_updates_per_training_iteration\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m loss_info \u001b[38;5;241m=\u001b[39m agent_learner\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     17\u001b[0m     iterations\u001b[38;5;241m=\u001b[39mnum_gradient_updates_per_training_iteration\n\u001b[1;32m     18\u001b[0m )\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/train/actor.py:167\u001b[0m, in \u001b[0;36mActor.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_time_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy_state\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    172\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_summaries\n\u001b[1;32m    173\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_interval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    174\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_summary \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_interval\n\u001b[1;32m    175\u001b[0m   ):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_metric_summaries()\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/drivers/py_driver.py:120\u001b[0m, in \u001b[0;36mPyDriver.run\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    117\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mget_initial_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    119\u001b[0m action_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39maction(time_step, policy_state)\n\u001b[0;32m--> 120\u001b[0m next_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# When using observer (for the purpose of training), only the previous\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# policy_state is useful. Therefore substitube it in the PolicyStep and\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# consume it w/ the observer.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m action_step_with_previous_state \u001b[38;5;241m=\u001b[39m action_step\u001b[38;5;241m.\u001b[39m_replace(state\u001b[38;5;241m=\u001b[39mpolicy_state)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/environments/py_environment.py:236\u001b[0m, in \u001b[0;36mPyEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_reset(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n\u001b[1;32m    233\u001b[0m ):\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[0;32m~/sbsim/smart_control/environment/environment.py:1297\u001b[0m, in \u001b[0;36mEnvironment._step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1291\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics_writer\u001b[38;5;241m.\u001b[39mwrite_action_response(\n\u001b[1;32m   1292\u001b[0m       action_response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_simulation_timestamp\n\u001b[1;32m   1293\u001b[0m   )\n\u001b[1;32m   1295\u001b[0m last_timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_simulation_timestamp\n\u001b[0;32m-> 1297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_observation()\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# We need to signal to the Actor that action was rejected and not to\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;66;03m# append this observation/action request to the trajectory.\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# Since TimeStep cannot be extended and it is checked for NaNs,\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;66;03m# we apply -inf as a reward to indicate the rejection.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;66;03m# This requires a specialized Actor extension class to handle the\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# rejection.\u001b[39;00m\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/simulator_building.py:268\u001b[0m, in \u001b[0;36mSimulatorBuilding.wait_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns after a certain amount of time.\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Update the building state.\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_step_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/simulator_flexible_floor_plan.py:156\u001b[0m, in \u001b[0;36mSimulatorFlexibleGeometries.execute_step_sim\u001b[0;34m(self, video_filename)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinite_differences_timestep(\n\u001b[1;32m    151\u001b[0m     ambient_temperature\u001b[38;5;241m=\u001b[39mambient_temperature,\n\u001b[1;32m    152\u001b[0m     convection_coefficient\u001b[38;5;241m=\u001b[39mconvection_coefficient,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Simulate airflow\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_building\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_convection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Reset the air handler and boiler flow rate demand before accumulating.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m hvac\u001b[38;5;241m.\u001b[39mair_handler\u001b[38;5;241m.\u001b[39mreset_demand()\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/building.py:893\u001b[0m, in \u001b[0;36mFloorPlanBasedBuilding.apply_convection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_convection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convection_simulator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convection_simulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_convection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_room_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/stochastic_convection_simulator.py:81\u001b[0m, in \u001b[0;36mStochasticConvectionSimulator.apply_convection\u001b[0;34m(self, room_dict, temp)\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuffle_no_max_dist(v, temp)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shuffle_max_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/stochastic_convection_simulator.py:133\u001b[0m, in \u001b[0;36mStochasticConvectionSimulator._shuffle_max_dist\u001b[0;34m(self, p, v, max_dist, temp)\u001b[0m\n\u001b[1;32m    131\u001b[0m       dist \u001b[38;5;241m=\u001b[39m (cv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m cv_2[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (cv[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m cv_2[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    132\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_dist:\n\u001b[0;32m--> 133\u001b[0m         \u001b[43mcandidates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[max_dist][val] \u001b[38;5;241m=\u001b[39m candidates\n\u001b[1;32m    136\u001b[0m swap_list\u001b[38;5;241m.\u001b[39mappend((val, random\u001b[38;5;241m.\u001b[39mchoice(candidates)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "num_gradient_updates_per_training_iteration = 100\n",
    "\n",
    "logging_info('Training.')\n",
    "\n",
    "for iter in range(num_episodes):\n",
    "    print('Training iteration: ', iter)\n",
    "    \n",
    "    _ = collect_env.reset()\n",
    "    collect_actor.run()\n",
    "    \n",
    "    logging_info(\n",
    "        'Executing %d gradient updates.'\n",
    "        %num_gradient_updates_per_training_iteration\n",
    "    )\n",
    "    loss_info = agent_learner.run(\n",
    "        iterations=num_gradient_updates_per_training_iteration\n",
    "    )\n",
    "    logging_info(\n",
    "        'Policy Gradient Loss: %6.2f, Value Estimation Loss: %6.2f, Clip Fraction: %6.2f '\n",
    "        % (\n",
    "            loss_info.extra.policy_gradient_loss.numpy(),\n",
    "            loss_info.extra.value_estimation_loss.numpy(),\n",
    "            loss_info.extra.clip_fraction.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logging_info('Evaluating.')\n",
    "    _ = eval_env.reset()\n",
    "    # Run the eval actor after the training iteration, and get its performance.\n",
    "    eval_actor.run_and_log()\n",
    "    replay_buffer.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(2,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_tensor_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.agents.ppo.ppo_policy.PPOPolicy at 0x78db6e8a2710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.greedy_policy.GreedyPolicy at 0x78db6e8a2ce0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = collect_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.expand_dims(time_step.observation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tfp.distributions.SquashToSpecNormal 'SquashToSpecNormal' batch_shape=[1] event_shape=? dtype=float32>,\n",
       " ())"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_actor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_actor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/train/actor.py:167\u001b[0m, in \u001b[0;36mActor.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_time_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy_state\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    172\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_summaries\n\u001b[1;32m    173\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_interval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    174\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_summary \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_interval\n\u001b[1;32m    175\u001b[0m   ):\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_metric_summaries()\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/drivers/py_driver.py:120\u001b[0m, in \u001b[0;36mPyDriver.run\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    117\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mget_initial_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    119\u001b[0m action_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39maction(time_step, policy_state)\n\u001b[0;32m--> 120\u001b[0m next_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# When using observer (for the purpose of training), only the previous\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# policy_state is useful. Therefore substitube it in the PolicyStep and\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# consume it w/ the observer.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m action_step_with_previous_state \u001b[38;5;241m=\u001b[39m action_step\u001b[38;5;241m.\u001b[39m_replace(state\u001b[38;5;241m=\u001b[39mpolicy_state)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tf_agents/environments/py_environment.py:236\u001b[0m, in \u001b[0;36mPyEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_reset(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n\u001b[1;32m    233\u001b[0m ):\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[0;32m~/sbsim/smart_control/environment/environment.py:1297\u001b[0m, in \u001b[0;36mEnvironment._step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1291\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics_writer\u001b[38;5;241m.\u001b[39mwrite_action_response(\n\u001b[1;32m   1292\u001b[0m       action_response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_simulation_timestamp\n\u001b[1;32m   1293\u001b[0m   )\n\u001b[1;32m   1295\u001b[0m last_timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_simulation_timestamp\n\u001b[0;32m-> 1297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_observation()\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# We need to signal to the Actor that action was rejected and not to\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;66;03m# append this observation/action request to the trajectory.\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# Since TimeStep cannot be extended and it is checked for NaNs,\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;66;03m# we apply -inf as a reward to indicate the rejection.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;66;03m# This requires a specialized Actor extension class to handle the\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# rejection.\u001b[39;00m\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/simulator_building.py:268\u001b[0m, in \u001b[0;36mSimulatorBuilding.wait_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns after a certain amount of time.\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Update the building state.\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_step_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/simulator_flexible_floor_plan.py:150\u001b[0m, in \u001b[0;36mSimulatorFlexibleGeometries.execute_step_sim\u001b[0;34m(self, video_filename)\u001b[0m\n\u001b[1;32m    145\u001b[0m convection_coefficient \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weather_controller\u001b[38;5;241m.\u001b[39mget_air_convection_coefficient(current_ts)\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Update each control volume.\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinite_differences_timestep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mambient_temperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambient_temperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvection_coefficient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvection_coefficient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Simulate airflow\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_building\u001b[38;5;241m.\u001b[39mapply_convection()\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/simulator.py:349\u001b[0m, in \u001b[0;36mSimulator.finite_differences_timestep\u001b[0;34m(self, ambient_temperature, convection_coefficient)\u001b[0m\n\u001b[1;32m    347\u001b[0m converged_successfully \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration_count \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iteration_limit):\n\u001b[0;32m--> 349\u001b[0m   temp_estimate, max_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_temperature_estimates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemp_estimate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m      \u001b[49m\u001b[43mambient_temperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambient_temperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconvection_coefficient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvection_coefficient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m iteration_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iteration_warning:\n\u001b[1;32m    355\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, not converged in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m steps, max_delta = \u001b[39m\u001b[38;5;132;01m%3.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    357\u001b[0m         iteration_count,\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iteration_warning,\n\u001b[1;32m    359\u001b[0m         max_delta,\n\u001b[1;32m    360\u001b[0m     )\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/tf_simulator.py:780\u001b[0m, in \u001b[0;36mTFSimulator.update_temperature_estimates\u001b[0;34m(self, temperature_estimates, ambient_temperature, convection_coefficient)\u001b[0m\n\u001b[1;32m    768\u001b[0m (\n\u001b[1;32m    769\u001b[0m     t_convection_left_edge,\n\u001b[1;32m    770\u001b[0m     t_convection_right_edge,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boundary_cv_mapping,\n\u001b[1;32m    777\u001b[0m )\n\u001b[1;32m    779\u001b[0m \u001b[38;5;66;03m# Create shifted tensor to be able to evaluate neighbors in the equation.\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m t_temp_left, t_temp_right, t_temp_above, t_temp_below \u001b[38;5;241m=\u001b[39m \u001b[43m_get_neighbor_temps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambient_temperature\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# Get the ambinet temperature as a tensor.\u001b[39;00m\n\u001b[1;32m    785\u001b[0m t_temp_inf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(ambient_temperature, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/tf_simulator.py:646\u001b[0m, in \u001b[0;36mTFSimulator.update_temperature_estimates.<locals>._get_neighbor_temps\u001b[0;34m(t_temp, ambient_temperature)\u001b[0m\n\u001b[1;32m    638\u001b[0m t_temp_right \u001b[38;5;241m=\u001b[39m shift_tensor_right(\n\u001b[1;32m    639\u001b[0m     t_temp, padding_value\u001b[38;5;241m=\u001b[39mambient_temperature\n\u001b[1;32m    640\u001b[0m )\n\u001b[1;32m    642\u001b[0m t_temp_above \u001b[38;5;241m=\u001b[39m shift_tensor_down(\n\u001b[1;32m    643\u001b[0m     t_temp, padding_value\u001b[38;5;241m=\u001b[39mambient_temperature\n\u001b[1;32m    644\u001b[0m )\n\u001b[0;32m--> 646\u001b[0m t_temp_below \u001b[38;5;241m=\u001b[39m \u001b[43mshift_tensor_up\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambient_temperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (t_temp_left, t_temp_right, t_temp_above, t_temp_below)\n",
      "File \u001b[0;32m~/sbsim/smart_control/simulator/tf_simulator.py:479\u001b[0m, in \u001b[0;36mshift_tensor_up\u001b[0;34m(x, padding_value)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshift_tensor_up\u001b[39m(\n\u001b[1;32m    476\u001b[0m     x: tf\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    477\u001b[0m     padding_value: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    478\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 479\u001b[0m   t_up \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mboolean_mask(t_up, [\u001b[38;5;28;01mFalse\u001b[39;00m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:3499\u001b[0m, in \u001b[0;36mpad_v2\u001b[0;34m(tensor, paddings, mode, constant_values, name)\u001b[0m\n\u001b[1;32m   3443\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   3444\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpad_v2\u001b[39m(tensor, paddings, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONSTANT\u001b[39m\u001b[38;5;124m\"\u001b[39m, constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3446\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Pads a tensor.\u001b[39;00m\n\u001b[1;32m   3447\u001b[0m \n\u001b[1;32m   3448\u001b[0m \u001b[38;5;124;03m  This operation pads a `tensor` according to the `paddings` you specify.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3497\u001b[0m \u001b[38;5;124;03m    ValueError: When mode is not one of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\".\u001b[39;00m\n\u001b[1;32m   3498\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3499\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:3570\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(tensor, paddings, mode, name, constant_values)\u001b[0m\n\u001b[1;32m   3568\u001b[0m     result \u001b[38;5;241m=\u001b[39m gen_array_ops\u001b[38;5;241m.\u001b[39mpad(tensor, paddings, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   3569\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3570\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREFLECT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3573\u001b[0m   result \u001b[38;5;241m=\u001b[39m gen_array_ops\u001b[38;5;241m.\u001b[39mmirror_pad(\n\u001b[1;32m   3574\u001b[0m       tensor, paddings, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREFLECT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:6906\u001b[0m, in \u001b[0;36mpad_v2\u001b[0;34m(input, paddings, constant_values, name)\u001b[0m\n\u001b[1;32m   6904\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   6905\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6906\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_v2_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6907\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6908\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[1;32m   6909\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:6933\u001b[0m, in \u001b[0;36mpad_v2_eager_fallback\u001b[0;34m(input, paddings, constant_values, name, ctx)\u001b[0m\n\u001b[1;32m   6931\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m, paddings, constant_values]\n\u001b[1;32m   6932\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTpaddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_Tpaddings)\n\u001b[0;32m-> 6933\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPadV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6934\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[1;32m   6936\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[1;32m   6937\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPadV2\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m~/sbsim/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_actor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
